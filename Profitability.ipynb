{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries relevant to data cleaning and analysis.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sqlite3\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open as a dataframe the file named tmdb.movies.csv that has details such a movie's \n",
    "# popularity and vote count.\n",
    "movie_rating_df = pd.read_csv(\"unzippedData/tmdb.movies.csv\")\n",
    "movie_rating_df = movie_rating_df.drop(columns='Unnamed: 0', axis=1)\n",
    "\n",
    "# Print the first 5 values\n",
    "movie_rating_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the shape (rows by columns) of the dataframe\n",
    "movie_rating_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Examine the schema and data types\n",
    "movie_rating_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Convert release_date from string data type to datetype\n",
    "movie_rating_df['release_date'] = pd.to_datetime(movie_rating_df['release_date'])\n",
    "movie_rating_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether there are missing values\n",
    "movie_rating_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate rows in movie_rating_df\n",
    "# Use keep='first' clause to avoid counting the first value in a set of repeated rows\n",
    "\n",
    "movie_rating_df.duplicated(keep='first').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates, keep the first row\n",
    "\n",
    "movie_rating_df.drop_duplicates(keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm whether duplicates have been removed\n",
    "movie_rating_df.duplicated(keep='first').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code from student.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA UNDERSTANDING FOR BOM.MOVIE_GROSS.CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open as a dataframe the file named bom.movie_gross that has details such\n",
    "# a movie's domestic gross income and foreign gross income\n",
    "movie_gross_df = pd.read_csv('unzippedData/bom.movie_gross.csv')\n",
    "\n",
    "# Print the first 5 rows\n",
    "movie_gross_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the last 5 rows\n",
    "movie_gross_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the shape (rows by columns) of the dataframe\n",
    "movie_gross_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the schema and data types\n",
    "movie_gross_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the missing values\n",
    "movie_gross_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether there are duplicated rows\n",
    "movie_gross_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the nature of the column values\n",
    "movie_gross_df.value_counts().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA UNDERSTANDING FOR TN.MOVIE_BUDGETS.CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open as a dataframe the file named bom.movie_gross that has details such\n",
    "# a movie's domestic gross income and foreign gross income\n",
    "# The column id doesn't represent an index, so we won't assign it the index column\n",
    "movie_budgets_df = pd.read_csv('unzippedData/tn.movie_budgets.csv')\n",
    "movie_budgets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the last 5 rows\n",
    "movie_budgets_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the shape (rows by columns) of the dataframe\n",
    "movie_budgets_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Examine the schema and data types\n",
    "movie_budgets_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert release_date from string data type to datetype\n",
    "movie_budgets_df['release_date'] = pd.to_datetime(movie_budgets_df['release_date'])\n",
    "movie_budgets_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_budgets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Examine missing values in movie_basics_df\n",
    "movie_budgets_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether there are duplicated rows\n",
    "movie_budgets_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA CLEANING OF MOVIE_GROSS_DF\n",
    "Cleaning this data set will first involve examining the kind of values in the studio column, as well as the percent of missing values, which will help in deciding how to handle the missing values.\n",
    "\n",
    "For the missing values in the domestic_gross and foreign_gross columns, an observation of the two datasets movie_gross_df and movie_budget_df shows that I will need to join the two tables at the rows where the names of movies match. This will enable me to analyse the budget, domestic revenue, worldwide revenue, and gross profitability of each movie. \n",
    "\n",
    "I will therefore, decide whether to replace the missing values or whole columns of domestic_gross and foreign_gross in movie_gross_df with the matching values from the dataframe movie_budgets_df, after joining the two dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the nature of values in studio column\n",
    "movie_gross_df['studio'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find percent of missing values in genres column\n",
    "missing_studios = (movie_gross_df['studio'].isna().sum())/ (len(movie_gross_df['studio']))\n",
    "print(f\"Percent of missing values in studios column is {missing_studios:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values in studio column are categorical and since only 5 (0.15%) are missing, I will replace the missing values with a generic category as a placeholder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_gross_df['studio'] = movie_gross_df['studio'].fillna('Generic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that there are no missing values in studio column\n",
    "movie_gross_df['studio'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA CLEANING OF MOVIE_BUDGETS_DF\n",
    "Cleaning this dataset will involve stripping the values in production_budget, domestic_gross, and worldwide_gross columns of the dollar ($) sign and converting them to the float datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use .replace() method to remove all occurences of , and $ signs\n",
    "# Convert the values to numeric (integer) type\n",
    "movie_budgets_df['production_budget'] = movie_budgets_df['production_budget'].str.replace(',', '').str.replace('$', '').apply(pd.to_numeric)\n",
    "movie_budgets_df['domestic_gross'] = movie_budgets_df['domestic_gross'].str.replace(',', '').str.replace('$', '').apply(pd.to_numeric)\n",
    "movie_budgets_df['worldwide_gross'] = movie_budgets_df['worldwide_gross'].str.replace(',', '').str.replace('$', '').apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm the data types of movie_budgets_df have changed\n",
    "movie_budgets_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA ANALYSIS OF MOVIE_GROSS_DF AND MOVIE_BUDGETS_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Since we need to combine the dateframes at the rows where movie names are common,\n",
    "# we will use inner merge instead of inner join.\n",
    "\n",
    "# Inner merge of movie_gross_df and movie_budgets_df\n",
    "merged_gross_and_budgets_df = movie_gross_df.merge(movie_budgets_df, left_on='title', \n",
    "                                                   right_on='movie', how='inner')\n",
    "merged_gross_and_budgets_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the id, and movie columns\n",
    "merged_gross_and_budgets_df.drop(labels=['id', 'movie'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in 'domestic_gross_y' and 'worldwide_gross' columns\n",
    "merged_gross_and_budgets_df[['domestic_gross_y', 'worldwide_gross']].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling the dataset to compare the different gross revenue columns\n",
    "\n",
    "# Create a new dataframe without missing values in 'domestic_gross_x' \n",
    "# and 'foreign_gross' columns\n",
    "sampling_df = merged_gross_and_budgets_df.dropna(subset=['domestic_gross_x', 'foreign_gross'], axis=0).copy()\n",
    "\n",
    "# Create a new column for sum of 'domestic_gross_x' and 'foreign_gross'\n",
    "sampling_df['total_gross_x'] = (sampling_df['domestic_gross_x'].apply(pd.to_numeric) + \n",
    "                               sampling_df['foreign_gross'].str.replace(',', '').apply(pd.to_numeric))\n",
    "\n",
    "# Perform random sampling of rows to compare domestic, foreign, and gross revenues\n",
    "sampling_df = sampling_df[sampling_df[\"foreign_gross\"].notna()].sample(5, random_state=2)\n",
    "sampling_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Samples of the sampling_df show that most values of the worldwide_gross column are closely comparable with the corresponding total_gross_x values found by adding domestic_gross_x and foreign_gross. We will therefore drop the domestic_gross_x and foreign_gross in the merged dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_gross_and_budgets_df.drop(labels=['domestic_gross_x', 'foreign_gross'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, since we want analyse profit distribution by studio, we will first find the profits by subtracting production budget from the world_wide gross in the marged dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a profits column\n",
    "merged_gross_and_budgets_df['profits'] = (merged_gross_and_budgets_df['worldwide_gross'] - \n",
    "                                          merged_gross_and_budgets_df['production_budget'])\n",
    "merged_gross_and_budgets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by studio and sort in descending order\n",
    "grouped_df = merged_gross_and_budgets_df.groupby('studio').sum([['production_budget'], ['profits']])\n",
    "grouped_and_sorted_df = grouped_df.sort_values(by='profits', ascending=False)\n",
    "grouped_and_sorted_df.reset_index(inplace=True)\n",
    "grouped_and_sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a bar chart of gross profit per studio\n",
    "\n",
    "labels= grouped_and_sorted_df['studio']\n",
    "values= grouped_and_sorted_df['profits']\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.xticks(rotation=90, fontsize=10, fontweight= 'bold')\n",
    "plt.title('Profit Distribution of Major Studios in the Movie Industry', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Studio', fontsize=10, fontweight='bold')\n",
    "plt.ylabel('Profit', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Create the color palette\n",
    "palette = sns.color_palette(\"Paired\")\n",
    "\n",
    "# Create the bar plot\n",
    "plt.bar(labels, values, color= palette, label='Studio')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests                 # Simpler HTTP requests \n",
    "from bs4 import BeautifulSoup   # Python package for pulling data out of HTML and XML files\n",
    "import pandas as pd             # Python package for data manipulation and analysis\n",
    "import re                       # regular expressions\n",
    "from datetime import datetime   # python package to retireve DateTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.imdb.com/chart/top'              # IMDb Top 250 list link\n",
    "url_text = requests.get(url).text                    # Get the session text for the link\n",
    "url_soup = BeautifulSoup(url_text, 'html.parser')   # Get data from the HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = 'https://www.imdb.com%s'\n",
    "\n",
    "# Get the title links for all the pages\n",
    "title_links = [template % a.attrs.get('href') for a in url_soup.select('td.titleColumn a')]\n",
    "\n",
    "imdb_movie_list = []\n",
    "# Getting the various fields and creating a list of objects with details\n",
    "#   - ranking | movie_name | url | year | rating | vote_count | summary | production | director | writer_1 | writer_2\n",
    "#   - genre_1 | genre_2 | genre_3 | genre_4 | release date | censor_rating | movie_length | country | language\n",
    "#   - budget | gross_worldwide | gross_usa | opening_week_usa\n",
    "\n",
    "for i in list(range(0, len(title_links))):\n",
    "    page_url = title_links[i]\n",
    "    page_text = requests.get(page_url).text\n",
    "    page_soup = BeautifulSoup(page_text, 'html.parser')\n",
    "    \n",
    "# Getting the box office details for language, budget, Opening Weekend USA, \n",
    "    # Gross income worldwide and USA, and production company\n",
    "    box_office_details = []\n",
    "    box_office_dictionary = {'Country':'','Budget':'','Gross USA':'','Cumulative Worldwide Gross':''}\n",
    "    for details in page_soup.find_all(\"div\",{\"class\":\"txt-block\"}):\n",
    "        detail = details.get_text(strip=True).split(':')\n",
    "        if detail[0] in box_office_dictionary:\n",
    "            box_office_details.append(detail)\n",
    "    \n",
    "    for detail in box_office_details: \n",
    "        if detail[0] in box_office_dictionary: \n",
    "            box_office_dictionary.update({detail[0] : detail[1]}) \n",
    "\n",
    "    country = box_office_dictionary['Country'].split(\"|\")\n",
    "    while len(country) < 4: country.append(' ')\n",
    "\n",
    "    budget = box_office_dictionary['Budget'].split('(')[0]\n",
    "\n",
    "    gross_usa = box_office_dictionary['Gross USA']\n",
    "    gross_worldwide = box_office_dictionary['Cumulative Worldwide Gross'].split(' ')[0]\n",
    "    \n",
    "    movie_dict = { 'country': country, 'budget': budget, 'gross_worldwide': gross_worldwide,\n",
    "        'gross_usa': gross_usa }\n",
    "\n",
    "    imdb_movie_list.append(movie_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_movie_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_box_office_data(url):\n",
    "    # Send an HTTP request to the URL and get the webpage's content\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find the table containing the movie data\n",
    "    table = soup.find('table', {'class': 'a-bordered a-horizontal-stripes a-size-base a-span12 mojo-body-table mojo-table-annotated'})\n",
    "\n",
    "    # Initialize lists to store data\n",
    "    ranks = []\n",
    "    titles = []\n",
    "    grosses = []\n",
    "    years = []\n",
    "    #budgets = []\n",
    "\n",
    "    # Loop through each row of the table\n",
    "    for row in table.find_all('tr')[1:]:  # Skipping the first row as it contains headers\n",
    "        columns = row.find_all('td')\n",
    "        \n",
    "        # Extract data from each column of the row\n",
    "        rank = columns[0].text.strip()\n",
    "        title = columns[1].text.strip()\n",
    "        gross = columns[2].text.strip()\n",
    "        year = columns[7].text.strip()\n",
    "        #budget = columns[9].text.strip()\n",
    "        \n",
    "        # Append data to respective lists\n",
    "        ranks.append(rank)\n",
    "        titles.append(title)\n",
    "        grosses.append(gross)\n",
    "        years.append(year)\n",
    "        #budgets.append(budget)\n",
    "\n",
    "    # Create a DataFrame to store the scraped data\n",
    "    data = {\n",
    "        'Rank': ranks,\n",
    "        'Title': titles,\n",
    "        'Worldwide Lifetime Gross': grosses,\n",
    "        'Year': years,\n",
    "    } #'Budget': budgets\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    url = 'https://www.boxofficemojo.com/chart/ww_top_lifetime_gross/?area=XWW'\n",
    "    df = scrape_box_office_data(url)\n",
    "    #df\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = 'https://www.boxofficemojo.com'\n",
    "\n",
    "def get_budget(movie_url):\n",
    "    response = requests.get(movie_url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    budget_element = soup.find('span', text='Budget')\n",
    "    if budget_element:\n",
    "        budget = budget_element.find_next('span').text.strip()\n",
    "        return budget\n",
    "    return 'N/A'\n",
    "\n",
    "def scrape_box_office_data(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    table = soup.find('table', {'class': 'a-bordered a-horizontal-stripes a-size-base a-span12 mojo-body-table mojo-table-annotated'})\n",
    "\n",
    "    ranks = []\n",
    "    titles = []\n",
    "    grosses = []\n",
    "    years = []\n",
    "    budgets = []\n",
    "\n",
    "    for row in table.find_all('tr')[1:]:\n",
    "        columns = row.find_all('td')\n",
    "        rank = columns[0].text.strip()\n",
    "        title_column = columns[1].find('a')\n",
    "        title = title_column.text.strip()\n",
    "        movie_url = BASE_URL + title_column['href']  # Get the URL for the movie's individual page\n",
    "        gross = columns[2].text.strip()\n",
    "        year = columns[7].text.strip()\n",
    "        budget = get_budget(movie_url)\n",
    "        \n",
    "        ranks.append(rank)\n",
    "        titles.append(title)\n",
    "        grosses.append(gross)\n",
    "        years.append(year)\n",
    "        budgets.append(budget)\n",
    "\n",
    "    data = {\n",
    "        'Rank': ranks,\n",
    "        'Title': titles,\n",
    "        'Worldwide Lifetime Gross': grosses,\n",
    "        'Year': years,\n",
    "        'Budget': budgets\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    url = 'https://www.boxofficemojo.com/chart/ww_top_lifetime_gross/?area=XWW'\n",
    "    df = scrape_box_office_data(url)\n",
    "    #print(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(200,1000, 200):\n",
    "    url = \"https://www.boxofficemojo.com/chart/ww_top_lifetime_gross/?area=XWW&offset={}.html\".format(i)\n",
    "    html_page = requests.get(url)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = 'https://www.boxofficemojo.com'\n",
    "\n",
    "def get_budget(movie_url):\n",
    "    response = requests.get(movie_url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    budget_element = soup.find('span', text='Budget')\n",
    "    if budget_element:\n",
    "        budget = budget_element.find_next('span').text.strip()\n",
    "        return budget\n",
    "    return 'N/A'\n",
    "\n",
    "def scrape_box_office_data(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    table = soup.find('table', {'class': 'a-bordered a-horizontal-stripes a-size-base a-span12 mojo-body-table mojo-table-annotated'})\n",
    "\n",
    "    ranks = []\n",
    "    titles = []\n",
    "    grosses = []\n",
    "    years = []\n",
    "    budgets = []\n",
    "\n",
    "    for row in table.find_all('tr')[1:]:\n",
    "        columns = row.find_all('td')\n",
    "        rank = columns[0].text.strip()\n",
    "        title_column = columns[1].find('a')\n",
    "        title = title_column.text.strip()\n",
    "        movie_url = BASE_URL + title_column['href']  # Get the URL for the movie's individual page\n",
    "        gross = columns[2].text.strip()\n",
    "        year = columns[7].text.strip()\n",
    "        budget = get_budget(movie_url)\n",
    "        \n",
    "        ranks.append(rank)\n",
    "        titles.append(title)\n",
    "        grosses.append(gross)\n",
    "        years.append(year)\n",
    "        budgets.append(budget)\n",
    "\n",
    "    data = {\n",
    "        'Rank': ranks,\n",
    "        'Title': titles,\n",
    "        'Worldwide Lifetime Gross': grosses,\n",
    "        'Year': years,\n",
    "        'Budget': budgets\n",
    "    }\n",
    "    df_page2_5 = pd.DataFrame(data)\n",
    "\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for i in range(200,600,200):\n",
    "        url = \"https://www.boxofficemojo.com/chart/ww_top_lifetime_gross/?area=XWW&offset={}.html\".format(i)\n",
    "        df_page2_5 = scrape_box_office_data(url)\n",
    "    df_all = pd.concat([df_all, df_page2_5], axis=0)\n",
    "    #print(df)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retry\n",
    "BASE_URL = 'https://www.boxofficemojo.com'\n",
    "\n",
    "def get_budget(movie_url):\n",
    "    response = requests.get(movie_url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    budget_element = soup.find('span', text='Budget')\n",
    "    if budget_element:\n",
    "        budget = budget_element.find_next('span').text.strip()\n",
    "        return budget\n",
    "    return 'N/A'\n",
    "\n",
    "def scrape_box_office_data(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    table = soup.find('table', {'class': 'a-bordered a-horizontal-stripes a-size-base a-span12 mojo-body-table mojo-table-annotated'})\n",
    "\n",
    "    ranks = []\n",
    "    titles = []\n",
    "    grosses = []\n",
    "    years = []\n",
    "    budgets = []\n",
    "\n",
    "    for row in table.find_all('tr')[1:]:\n",
    "        columns = row.find_all('td')\n",
    "        rank = columns[0].text.strip()\n",
    "        title_column = columns[1].find('a')\n",
    "        title = title_column.text.strip()\n",
    "        movie_url = BASE_URL + title_column['href']  # Get the URL for the movie's individual page\n",
    "        gross = columns[2].text.strip()\n",
    "        year = columns[7].text.strip()\n",
    "        budget = get_budget(movie_url)\n",
    "        \n",
    "        ranks.append(rank)\n",
    "        titles.append(title)\n",
    "        grosses.append(gross)\n",
    "        years.append(year)\n",
    "        budgets.append(budget)\n",
    "\n",
    "    data = {\n",
    "        'Rank': ranks,\n",
    "        'Title': titles,\n",
    "        'Worldwide Lifetime Gross': grosses,\n",
    "        'Year': years,\n",
    "        'Budget': budgets\n",
    "    }\n",
    "\n",
    "    return data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for i in range(200,1000,200):\n",
    "        url = \"https://www.boxofficemojo.com/chart/ww_top_lifetime_gross/?area=XWW&offset={}.html\".format(i)\n",
    "        data = scrape_box_office_data(url)\n",
    "        df_all = pd.DataFrame(data)\n",
    "    #print(df)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = 'https://www.boxofficemojo.com'\n",
    "\n",
    "# Define a function for getting the budget, which is on\n",
    "# a movie's individual page\n",
    "def get_budget(movie_url):\n",
    "    response = requests.get(movie_url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    budget_element = soup.find('span', text='Budget')\n",
    "    if budget_element:\n",
    "        budget = budget_element.find_next('span').text.strip()\n",
    "        return budget\n",
    "    return 'N/A'\n",
    "\n",
    "# Define a function to scrape rank, title, worldwide lifetime gross,\n",
    "# year, and budget values\n",
    "def scrape_box_office_data(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    table = soup.find('table', {'class': 'a-bordered a-horizontal-stripes a-size-base a-span12 mojo-body-table mojo-table-annotated'})\n",
    "\n",
    "    # Define empty lists for rank, title, gross, year, and budget values\n",
    "    ranks = []\n",
    "    titles = []\n",
    "    grosses = []\n",
    "    years = []\n",
    "    budgets = []\n",
    "\n",
    "    # Iterate over the rows in table tag\n",
    "    for row in table.find_all('tr')[1:]:\n",
    "        \n",
    "        # Get the values in rank, title, worldwide lifetime gross,\n",
    "        # and year columns in a row\n",
    "        columns = row.find_all('td')\n",
    "        rank = columns[0].text.strip()\n",
    "        title_column = columns[1].find('a')\n",
    "        title = title_column.text.strip()\n",
    "        gross = columns[2].text.strip()\n",
    "        year = columns[7].text.strip()\n",
    "        \n",
    "        # Get the URL for the movie's individual page\n",
    "        movie_url = BASE_URL + title_column['href']  \n",
    "        budget = get_budget(movie_url)\n",
    "        \n",
    "        # Append the respective lists\n",
    "        ranks.append(rank)\n",
    "        titles.append(title)\n",
    "        grosses.append(gross)\n",
    "        years.append(year)\n",
    "        budgets.append(budget)\n",
    "\n",
    "    # Add the lists values to a dictionary named data, each value at the corresponding key\n",
    "    data = {\n",
    "        'Rank': ranks,\n",
    "        'Title': titles,\n",
    "        'Worldwide Lifetime Gross': grosses,\n",
    "        'Year': years,\n",
    "        'Budget': budgets\n",
    "    }\n",
    "    \n",
    "    # Convert the dictionary \n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    url = 'https://www.boxofficemojo.com/chart/ww_top_lifetime_gross/?area=XWW'\n",
    "    df = scrape_box_office_data(url)\n",
    "    #print(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 800 rows\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "BASE_URL = 'https://www.boxofficemojo.com'\n",
    "RESULTS_PER_PAGE = 200\n",
    "\n",
    "def get_budget(movie_url):\n",
    "    response = requests.get(movie_url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    budget_element = soup.find('span', text='Budget')\n",
    "    if budget_element:\n",
    "        budget = budget_element.find_next('span').text.strip()\n",
    "        return budget\n",
    "    return 'N/A'\n",
    "\n",
    "def scrape_box_office_data(url):\n",
    "    ranks = []\n",
    "    titles = []\n",
    "    grosses = []\n",
    "    years = []\n",
    "    budgets = []\n",
    "\n",
    "    for offset in range(0, 800, RESULTS_PER_PAGE):\n",
    "        page_url = url + f'&offset={offset}'\n",
    "        response = requests.get(page_url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        table = soup.find('table', {'class': 'a-bordered a-horizontal-stripes a-size-base a-span12 mojo-body-table mojo-table-annotated'})\n",
    "\n",
    "        for row in table.find_all('tr')[1:]:\n",
    "            columns = row.find_all('td')\n",
    "            rank = columns[0].text.strip()\n",
    "            title_column = columns[1].find('a')\n",
    "            title = title_column.text.strip()\n",
    "            gross = columns[2].text.strip()\n",
    "            year = columns[7].text.strip()\n",
    "            \n",
    "            movie_url = BASE_URL + title_column['href']\n",
    "            budget = get_budget(movie_url)\n",
    "            \n",
    "            ranks.append(rank)\n",
    "            titles.append(title)\n",
    "            grosses.append(gross)\n",
    "            years.append(year)\n",
    "            budgets.append(budget)\n",
    "\n",
    "    data = {\n",
    "        'Rank': ranks,\n",
    "        'Title': titles,\n",
    "        'Worldwide Lifetime Gross': grosses,\n",
    "        'Year': years,\n",
    "        'Budget': budgets\n",
    "    }\n",
    "    df_all_pages = pd.DataFrame(data)\n",
    "\n",
    "    return df_all_pages\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    url = 'https://www.boxofficemojo.com/chart/ww_top_lifetime_gross/?area=XWW'\n",
    "    df_all_pages = scrape_box_office_data(url)\n",
    "df_all_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_pages.to_csv('BOM_800_movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1000 rows\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Set the base URL to be used to complete the the different URLs needed\n",
    "BASE_URL = 'https://www.boxofficemojo.com'\n",
    "\n",
    "# The website has 200 results per page\n",
    "RESULTS_PER_PAGE = 200\n",
    "\n",
    "# Define a function for scraping the budget, which is on\n",
    "# a movie's individual page\n",
    "def get_budget(movie_url):\n",
    "    response = requests.get(movie_url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    budget_element = soup.find('span', text='Budget')\n",
    "    if budget_element:\n",
    "        budget = budget_element.find_next('span').text.strip()\n",
    "        return budget\n",
    "    return 'N/A'\n",
    "\n",
    "# Define a function to scrape rank, title, worldwide lifetime gross,\n",
    "# year, and budget values\n",
    "def scrape_box_office_data(url):\n",
    "    \n",
    "    # Define empty lists for rank, title, gross, year, and budget values\n",
    "    ranks = []\n",
    "    titles = []\n",
    "    grosses = []\n",
    "    years = []\n",
    "    budgets = []\n",
    "\n",
    "    # Increment an offset parameter by 200, since each page has 200 results\n",
    "    for offset in range(0, 1000, RESULTS_PER_PAGE):\n",
    "        page_url = url + f'&offset={offset}'\n",
    "        response = requests.get(page_url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        table = soup.find('table', {'class': \n",
    "                                    'a-bordered a-horizontal-stripes a-size-base a-span12 mojo-body-table mojo-table-annotated'\n",
    "                                   })\n",
    "        # Iterate over the rows in <table></table> tag\n",
    "        for row in table.find_all('tr')[1:]:\n",
    "            # Get the values in rank, title, worldwide lifetime gross,\n",
    "            # and year columns in each row\n",
    "            columns = row.find_all('td')\n",
    "            rank = columns[0].text.strip()\n",
    "            title_column = columns[1].find('a')\n",
    "            title = title_column.text.strip()\n",
    "            gross = columns[2].text.strip()\n",
    "            year = columns[7].text.strip()\n",
    "            \n",
    "            # Define the URL for the movie's individual page\n",
    "            # and scrape the budget data\n",
    "            movie_url = BASE_URL + title_column['href']\n",
    "            budget = get_budget(movie_url)\n",
    "            \n",
    "            # Append the respective lists\n",
    "            ranks.append(rank)\n",
    "            titles.append(title)\n",
    "            grosses.append(gross)\n",
    "            years.append(year)\n",
    "            budgets.append(budget)\n",
    "            \n",
    "            #Delay the start of each cycle by 0.1 sec\n",
    "            time.sleep(0.1)\n",
    "            \n",
    "    # Add the lists values to a dictionary named data, each value at the corresponding key\n",
    "    data = {\n",
    "        'Rank': ranks,\n",
    "        'Title': titles,\n",
    "        'Worldwide Lifetime Gross': grosses,\n",
    "        'Year': years,\n",
    "        'Budget': budgets\n",
    "    }\n",
    "    # Convert the dictionary into a dataframe \n",
    "    df_all_pages = pd.DataFrame(data)\n",
    "    \n",
    "    # Return the dataframe\n",
    "    return df_all_pages\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    url = 'https://www.boxofficemojo.com/chart/ww_top_lifetime_gross/?area=XWW'\n",
    "    df_all_pages = scrape_box_office_data(url)\n",
    "df_all_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "800 rows Ã— 5 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1000 rows\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Set the initial URL to be scraped\n",
    "url = 'https://www.boxofficemojo.com/chart/ww_top_lifetime_gross/?area=XWW'\n",
    "\n",
    "# Set the base URL to be used to complete the different URLs needed\n",
    "BASE_URL = 'https://www.boxofficemojo.com'\n",
    "\n",
    "# The website has 200 results per page\n",
    "RESULTS_PER_PAGE = 200\n",
    "\n",
    "# Define a function for scraping the budget, which is on\n",
    "# a movie's individual page\n",
    "def get_budget(movie_url):\n",
    "    response = requests.get(movie_url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    budget_element = soup.find('span', text='Budget')\n",
    "    if budget_element:\n",
    "        budget = budget_element.find_next('span').text.strip()\n",
    "        return budget\n",
    "    return 'N/A'\n",
    "    \n",
    "# Define empty lists for rank, title, gross, year, and budget values\n",
    "ranks = []\n",
    "titles = []\n",
    "grosses = []\n",
    "years = []\n",
    "budgets = []\n",
    "\n",
    "# Increment an offset parameter by 200, since each page has 200 results\n",
    "for offset in range(0, 1000, RESULTS_PER_PAGE):\n",
    "    page_url = url + f'&offset={offset}'\n",
    "    response = requests.get(page_url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    table = soup.find('table', {'class': \n",
    "                                'a-bordered a-horizontal-stripes a-size-base a-span12 mojo-body-table mojo-table-annotated'\n",
    "                               })\n",
    "    # Iterate over the rows in <table></table> tag\n",
    "    for row in table.find_all('tr')[1:]:\n",
    "        # Get the values in rank, title, worldwide lifetime gross,\n",
    "        # and year columns in each row\n",
    "        columns = row.find_all('td')\n",
    "        rank = columns[0].text.strip()\n",
    "        title_column = columns[1].find('a')\n",
    "        title = title_column.text.strip()\n",
    "        gross = columns[2].text.strip()\n",
    "        year = columns[7].text.strip()\n",
    "\n",
    "        # Define the URL for the movie's individual page\n",
    "        # and scrape the budget data\n",
    "        movie_url = BASE_URL + title_column['href']\n",
    "        budget = get_budget(movie_url)\n",
    "\n",
    "        # Append the respective lists\n",
    "        ranks.append(rank)\n",
    "        titles.append(title)\n",
    "        grosses.append(gross)\n",
    "        years.append(year)\n",
    "        budgets.append(budget)\n",
    "\n",
    "        #Delay the start of each cycle by 0.1 sec\n",
    "        time.sleep(0.1)\n",
    "\n",
    "# Add the lists values to a dictionary named data, each value at the corresponding key\n",
    "data = {\n",
    "    'Rank': ranks,\n",
    "    'Title': titles,\n",
    "    'Worldwide Lifetime Gross': grosses,\n",
    "    'Year': years,\n",
    "    'Budget': budgets\n",
    "}\n",
    "# Convert the data to a dataframe\n",
    "df_all_pages = pd.DataFrame(data)\n",
    "\n",
    "# Print the dataframe\n",
    "df_all_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "        'Age': [25, 30, 35],\n",
    "        'City': ['New York', 'San Francisco', 'Los Angeles']}\n",
    "\n",
    "df_index = pd.DataFrame(data)\n",
    "\n",
    "# Group the DataFrame by 'City' column\n",
    "grouped_df = df_index.groupby('City').mean()\n",
    "\n",
    "# Reset the index and move the 'City' column back into the DataFrame\n",
    "grouped_df.reset_index(drop=False, inplace=True)\n",
    "\n",
    "# Output the DataFrame with the 'City' column back as a regular column\n",
    "print(grouped_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
